{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6dbd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import timm \n",
    "import torch\n",
    "\n",
    "# I'm adding this in\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "METADATA_SUBSET_PATH = \"/Users/franceskoback/Documents/xray_test/metadata_100subset_df.csv\"\n",
    "\n",
    "def get_manufacturer_labels(encoder, target_variable = \"(0008, 0070) Manufacturer\"):\n",
    "    df = pd.read_csv(METADATA_SUBSET_PATH)\n",
    "    df[\"id\"] = df[\"id\"].astype(\"str\").str.zfill(8)\n",
    "    df[\"code\"] = encoder.fit_transform(df[target_variable])\n",
    "    \n",
    "    return {row[\"id\"]: row[\"code\"] for i, row in df.iterrows()}\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #self.img_dir = \"/Users/franceskoback/Documents/research/pytorch_1/imagezz\"\n",
    "        self.img_dir = \"/Users/franceskoback/Documents/xray_test/xray_subsets\"\n",
    "\n",
    "        self.images = glob.glob(os.path.join(self.img_dir, \"*.npy\")) \n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.label_map = get_manufacturer_labels(self.le)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.fromarray(np.load(img_path)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "        xray_id = os.path.basename(img_path).replace(\".npy\", \"\")\n",
    "        \n",
    "        return {\"image\": image, \"label\": self.label_map[xray_id]}\n",
    "\n",
    "def train_val_dataset(dataset, val_split=0.20):\n",
    "    train_idx, rem_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    Test_size=0.5 # split equally between validation and test sets\n",
    "    val_idx, test_idx= train_test_split(list(rem_idx), test_size=Test_size)\n",
    "\n",
    "\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    datasets['test']= Subset(dataset, test_idx)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7225df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "80\n",
      "Training length 80\n",
      "Validation length 10\n",
      "Testing Length 10\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset()\n",
    "datasets = train_val_dataset(dataset)\n",
    "print(len(datasets['train'].dataset)) #6\n",
    "#datasets['train'].dataset, batch_size=params[\"batch_size\"], shuffle=True\n",
    "train_loader = DataLoader(\n",
    "    datasets['train'], batch_size=1, shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    datasets['val'], batch_size=1, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    datasets['test'], batch_size=1, shuffle= True\n",
    ")\n",
    "print(len(train_loader.dataset)) #6 \n",
    "len_train=len(datasets['train'])\n",
    "len_val= len(datasets['val'])\n",
    "print(\"Training length\", len(train_loader))\n",
    "print(\"Validation length\", len(valid_loader))\n",
    "print(\"Testing Length\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80723e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def Net(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    #model=timm.create_model(model,pretrained= True)\n",
    "    #model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    #model= efn.EfficientNetB0(weights='imagenet')\n",
    "    # Freeze parameters so we don't backprop through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                              ('fc1', nn.Linear(2048, 1024)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('fc2', nn.Linear(1024, 256)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('fc3', nn.Linear(256, num_classes)),\n",
    "                              ('output', nn.LogSoftmax(dim=1))\n",
    "                              ]))\n",
    "\n",
    "    model.fc = classifier\n",
    "    return model\n",
    "\n",
    "params = {\n",
    "    \"model\": \"resnet50\",\n",
    "    #\"device\": \"cuda\",\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 3, #64\n",
    "    \"num_workers\": 1, #20\n",
    "    \"n_epochs\": 50, #100\n",
    "    \"image_size\": 224, \n",
    "    \"in_channels\": 3, #3\n",
    "    \"num_classes\": 3, #12\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "model = Net(params['num_classes'])\n",
    "model.to(params[\"device\"])\n",
    "#loss_fn = nn.NLLLoss() # we want MSE loss i think \n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dee2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device = \"cpu\"):\n",
    "    #put model in training state\n",
    "    model.train()\n",
    "    #i=0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "\n",
    "    for batch_idx, img_dicts in enumerate(train_loader,0):  #used to be enumerate(train_loader)\n",
    "        inputs = img_dicts[\"image\"] #ORIGINAL ONE\n",
    "        labels = img_dicts[\"label\"]  # ORIGINAL ONE\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        #print(inputs.shape, labels.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() # do we need this or not? sets all grads to None \n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "         #   print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            #running_loss=0\n",
    "          #  i=i+1\n",
    "\n",
    "        \n",
    "        \n",
    "        #\n",
    "    \n",
    "        train_loss+= ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "        if batch_idx%5==0:\n",
    "            print('train loss', train_loss)\n",
    "    \n",
    "    print('Epoch {} avg Training loss: {:.3f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "    return model, train_loss\n",
    "\n",
    "def test_one_epoch(epoch, model, loss_fn, loader, len_val, device = \"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    #pbar = tqdm(enumerate(test_loader), total = len(test_loader))\n",
    "    running_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    #for step, (imgs, labels) in pbar:\n",
    "    for batch_idx, img_dicts in enumerate(loader,0):    \n",
    "        inputs = img_dicts[\"image\"] #ORIGINAL ONE\n",
    "        labels = img_dicts[\"label\"]  # ORIGINAL ONE\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        \n",
    "        log_preds = model(inputs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "        \n",
    "        preds = torch.exp(log_preds)\n",
    "        running_loss+=((1 / (batch_idx + 1)) * (loss.data.item() - running_loss))\n",
    "        \n",
    "        #calculate accuracy\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "        actual_labels+= list(labels.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    \n",
    "    accuracy = ((np.array(pred_labels)==np.array(actual_labels)).sum())/len_val #size of test set\n",
    "    correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "    total = len_val\n",
    "    \n",
    "    \n",
    "    return running_loss, accuracy, correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f203fbb",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1d563e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.2072925567626953\n",
      "train loss 62.324062426884964\n",
      "train loss 41.85218898816542\n",
      "train loss 37.22431609034538\n",
      "train loss 36.879116626012895\n",
      "train loss 38.32061140353863\n",
      "train loss 38.05710351082586\n",
      "train loss 35.184167351987625\n",
      "train loss 33.69456536886169\n",
      "train loss 32.84941823586174\n",
      "train loss 32.6957470482471\n",
      "train loss 35.57555202926908\n",
      "train loss 34.279155236775765\n",
      "train loss 34.906026592760384\n",
      "train loss 33.34937574326153\n",
      "train loss 32.544797011111925\n",
      "Epoch 1 avg Training loss: 32.487\n",
      "Epoch 1 avg Valid loss: 35.040\n",
      "Epoch 1 Valid accuracy: 30.0% (3 of 10 right)\n",
      "\n",
      "train loss 25.99591636657715\n",
      "train loss 22.066277265548703\n",
      "train loss 16.473410216244783\n",
      "train loss 22.473840169608593\n",
      "train loss 30.396940180233543\n",
      "train loss 26.22878291056706\n",
      "train loss 28.010390135549727\n",
      "train loss 28.90860344966252\n",
      "train loss 30.046005592113584\n",
      "train loss 27.98910421392192\n",
      "train loss 30.373644805422014\n",
      "train loss 29.490310219781737\n",
      "train loss 29.54490993257429\n",
      "train loss 32.14822396545699\n",
      "train loss 32.785186890145425\n",
      "train loss 31.117978863025964\n",
      "Epoch 2 avg Training loss: 32.012\n",
      "Epoch 2 avg Valid loss: 35.039\n",
      "Epoch 2 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 50.39034652709961\n",
      "train loss 25.46529918909073\n",
      "train loss 29.561762939799916\n",
      "train loss 29.07328526675701\n",
      "train loss 37.36742259207226\n",
      "train loss 35.580902828620026\n",
      "train loss 33.29980193030449\n",
      "train loss 29.919546481635827\n",
      "train loss 28.007509990436272\n",
      "train loss 29.075748127439745\n",
      "train loss 27.68403688832825\n",
      "train loss 29.318774414913992\n",
      "train loss 30.200413012113728\n",
      "train loss 29.997122168540955\n",
      "train loss 31.76573410504301\n",
      "train loss 32.14929455361868\n",
      "Epoch 3 avg Training loss: 32.012\n",
      "Epoch 3 avg Valid loss: 35.039\n",
      "Epoch 3 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2069653272628784\n",
      "train loss 11.869009256362915\n",
      "train loss 25.816568157889627\n",
      "train loss 27.572425693273544\n",
      "train loss 24.645737829662504\n",
      "train loss 24.352279869409706\n",
      "train loss 26.35931016937379\n",
      "train loss 28.064310842090187\n",
      "train loss 28.76808985558952\n",
      "train loss 27.328051797721695\n",
      "train loss 26.899731004939362\n",
      "train loss 29.033065293516433\n",
      "train loss 29.479332501771022\n",
      "train loss 30.978774648724183\n",
      "train loss 29.845078836024648\n",
      "train loss 30.907448018852033\n",
      "Epoch 4 avg Training loss: 32.012\n",
      "Epoch 4 avg Valid loss: 35.039\n",
      "Epoch 4 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.995849609375\n",
      "train loss 30.862071911493935\n",
      "train loss 29.851163549856707\n",
      "train loss 35.14551284909249\n",
      "train loss 39.270858810061505\n",
      "train loss 34.68816498151193\n",
      "train loss 38.08537433608886\n",
      "train loss 38.36167943146494\n",
      "train loss 35.19579825459458\n",
      "train loss 33.29194344385811\n",
      "train loss 34.317601152494845\n",
      "train loss 35.595726145165315\n",
      "train loss 33.94368870922778\n",
      "train loss 33.123693383101276\n",
      "train loss 32.30651530077761\n",
      "train loss 31.986232610125303\n",
      "Epoch 5 avg Training loss: 32.012\n",
      "Epoch 5 avg Valid loss: 35.040\n",
      "Epoch 5 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2070515155792236\n",
      "train loss 36.596953213214874\n",
      "train loss 38.35966461355036\n",
      "train loss 35.52157834172249\n",
      "train loss 37.633914992922826\n",
      "train loss 38.5340197453132\n",
      "train loss 37.11829428518972\n",
      "train loss 37.97337336341539\n",
      "train loss 37.36156010046236\n",
      "train loss 35.796097737291575\n",
      "train loss 33.74553803135366\n",
      "train loss 33.67508531468255\n",
      "train loss 31.93134462637979\n",
      "train loss 31.124452719182674\n",
      "train loss 30.38598191402327\n",
      "train loss 30.639235714548505\n",
      "Epoch 6 avg Training loss: 32.012\n",
      "Epoch 6 avg Valid loss: 35.038\n",
      "Epoch 6 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 82.78478240966797\n",
      "train loss 42.12736217180888\n",
      "train loss 37.26734872297808\n",
      "train loss 37.17018246650696\n",
      "train loss 38.490188553219745\n",
      "train loss 39.410296774827515\n",
      "train loss 34.71872208195348\n",
      "train loss 32.507985393206276\n",
      "train loss 31.53862139655322\n",
      "train loss 29.527995062910986\n",
      "train loss 32.52223055502947\n",
      "train loss 32.01823830178806\n",
      "train loss 33.96353493753026\n",
      "train loss 33.26922503926537\n",
      "train loss 32.424935502065736\n",
      "train loss 31.986217548972682\n",
      "Epoch 7 avg Training loss: 32.012\n",
      "Epoch 7 avg Valid loss: 35.038\n",
      "Epoch 7 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.995849609375\n",
      "train loss 20.866699417432148\n",
      "train loss 34.50547712499446\n",
      "train loss 36.04605808854103\n",
      "train loss 35.67260332334609\n",
      "train loss 35.580926996011\n",
      "train loss 36.17671145931367\n",
      "train loss 36.18485190471013\n",
      "train loss 36.659229830997745\n",
      "train loss 34.422388701335244\n",
      "train loss 33.64347969550713\n",
      "train loss 32.23957407474518\n",
      "train loss 33.68161888787003\n",
      "train loss 33.044945624741636\n",
      "train loss 31.636206709163297\n",
      "train loss 31.11798165973865\n",
      "Epoch 8 avg Training loss: 32.012\n",
      "Epoch 8 avg Valid loss: 35.038\n",
      "Epoch 8 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 1.206952691078186\n",
      "train loss 33.5967783331871\n",
      "train loss 28.107213724743236\n",
      "train loss 25.723801121115685\n",
      "train loss 25.10312633287339\n",
      "train loss 30.9969213283979\n",
      "train loss 27.997644405211176\n",
      "train loss 26.86437075336774\n",
      "train loss 32.074511071530786\n",
      "train loss 31.509621026723284\n",
      "train loss 30.702552138590345\n",
      "train loss 28.790098200951306\n",
      "train loss 29.747855846999123\n",
      "train loss 28.476196789380282\n",
      "train loss 30.31819140071601\n",
      "train loss 31.065333934206716\n",
      "Epoch 9 avg Training loss: 32.012\n",
      "Epoch 9 avg Valid loss: 35.038\n",
      "Epoch 9 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 9.601398468017578\n",
      "train loss 21.93242198228836\n",
      "train loss 19.090546347878195\n",
      "train loss 17.70001769810915\n",
      "train loss 19.73288877805074\n",
      "train loss 22.875553635450512\n",
      "train loss 24.772288114793838\n",
      "train loss 25.064681470394135\n",
      "train loss 26.368551864856627\n",
      "train loss 27.354070751563363\n",
      "train loss 26.45288355210248\n",
      "train loss 29.4472968599626\n",
      "train loss 30.98707009338942\n",
      "train loss 30.39105973279838\n",
      "train loss 31.681225039589577\n",
      "train loss 32.19136149632304\n",
      "Epoch 10 avg Training loss: 32.012\n",
      "Epoch 10 avg Valid loss: 35.038\n",
      "Epoch 10 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 9.601398468017578\n",
      "train loss 34.46297472715378\n",
      "train loss 41.194332090291105\n",
      "train loss 36.84532702714204\n",
      "train loss 32.18698711054665\n",
      "train loss 37.02619772690993\n",
      "train loss 32.757775479747394\n",
      "train loss 32.99663306938276\n",
      "train loss 34.56200587167971\n",
      "train loss 34.665514212587595\n",
      "train loss 37.53249827786987\n",
      "train loss 37.25973369181155\n",
      "train loss 35.82526416465883\n",
      "train loss 35.28078040029062\n",
      "train loss 34.54260411396831\n",
      "train loss 33.23327947604027\n",
      "Epoch 11 avg Training loss: 32.012\n",
      "Epoch 11 avg Valid loss: 35.039\n",
      "Epoch 11 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.20697820186615\n",
      "train loss 29.99818895260493\n",
      "train loss 32.79743270440535\n",
      "train loss 35.07160912454128\n",
      "train loss 31.482829105286374\n",
      "train loss 33.61186510782976\n",
      "train loss 35.41532652608811\n",
      "train loss 32.04132946332297\n",
      "train loss 31.704283644513396\n",
      "train loss 30.536338191965363\n",
      "train loss 28.899525371252327\n",
      "train loss 29.04746100732259\n",
      "train loss 28.436900703633423\n",
      "train loss 30.433370144078236\n",
      "train loss 30.261909224617657\n",
      "train loss 31.612644084190073\n",
      "Epoch 12 avg Training loss: 32.012\n",
      "Epoch 12 avg Valid loss: 35.038\n",
      "Epoch 12 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 82.78475952148438\n",
      "train loss 37.394926627477005\n",
      "train loss 37.340296517718926\n",
      "train loss 40.86911676079035\n",
      "train loss 37.72826256638481\n",
      "train loss 36.810598245033844\n",
      "train loss 34.705532454675236\n",
      "train loss 33.07409496770964\n",
      "train loss 34.240095356615576\n",
      "train loss 33.413788834343784\n",
      "train loss 32.95331601301829\n",
      "train loss 32.29664761679513\n",
      "train loss 31.544442724009023\n",
      "train loss 31.83920494715372\n",
      "train loss 32.374141238105125\n",
      "train loss 33.04384482691162\n",
      "Epoch 13 avg Training loss: 32.012\n",
      "Epoch 13 avg Valid loss: 35.038\n",
      "Epoch 13 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.206950068473816\n",
      "train loss 19.46760723988215\n",
      "train loss 20.400395610115744\n",
      "train loss 20.02484392374754\n",
      "train loss 24.093738958949135\n",
      "train loss 22.091155359378227\n",
      "train loss 22.618261460335024\n",
      "train loss 22.321322457657917\n",
      "train loss 24.222892322191377\n",
      "train loss 26.415305192055907\n",
      "train loss 27.15849700862286\n",
      "train loss 29.547150826879907\n",
      "train loss 30.72477702039187\n",
      "train loss 29.9486802816391\n",
      "train loss 30.31264401993281\n",
      "train loss 31.11797237239386\n",
      "Epoch 14 avg Training loss: 32.012\n",
      "Epoch 14 avg Valid loss: 35.039\n",
      "Epoch 14 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.995849609375\n",
      "train loss 55.72363313039144\n",
      "train loss 35.95873108777133\n",
      "train loss 40.11911857128144\n",
      "train loss 34.05286893390475\n",
      "train loss 33.33443167117926\n",
      "train loss 36.25348523739846\n",
      "train loss 35.34016353554196\n",
      "train loss 34.45447692929245\n",
      "train loss 34.230713833933294\n",
      "train loss 33.917710739023555\n",
      "train loss 33.16060048767499\n",
      "train loss 32.239218262375374\n",
      "train loss 30.875705157265518\n",
      "train loss 32.14304737473877\n",
      "train loss 32.475468772022346\n",
      "Epoch 15 avg Training loss: 32.012\n",
      "Epoch 15 avg Valid loss: 35.039\n",
      "Epoch 15 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 82.78475189208984\n",
      "train loss 41.79400062561035\n",
      "train loss 33.77817398851568\n",
      "train loss 38.61998878419399\n",
      "train loss 37.823505299431936\n",
      "train loss 36.057076201989105\n",
      "train loss 32.64146777122252\n",
      "train loss 31.319005943006946\n",
      "train loss 29.226684340616558\n",
      "train loss 30.823156100252405\n",
      "train loss 32.780993980519916\n",
      "train loss 31.961140892335344\n",
      "train loss 33.98315831872283\n",
      "train loss 33.984120612794705\n",
      "train loss 33.43862613489931\n",
      "train loss 31.77049777852862\n",
      "Epoch 16 avg Training loss: 32.012\n",
      "Epoch 16 avg Valid loss: 35.039\n",
      "Epoch 16 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 82.78482055664062\n",
      "train loss 56.657919406890876\n",
      "train loss 48.321128888563685\n",
      "train loss 39.820696175098426\n",
      "train loss 40.12867175965083\n",
      "train loss 40.025673297735366\n",
      "train loss 36.35706311656583\n",
      "train loss 37.473176327016624\n",
      "train loss 38.102366011317194\n",
      "train loss 37.3516576860262\n",
      "train loss 37.19526100626179\n",
      "train loss 35.19580942392349\n",
      "train loss 32.73747882686678\n",
      "train loss 33.941648692795724\n",
      "train loss 32.379698486395284\n",
      "train loss 31.7704904142179\n",
      "Epoch 17 avg Training loss: 32.012\n",
      "Epoch 17 avg Valid loss: 35.038\n",
      "Epoch 17 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 9.601405143737793\n",
      "train loss 31.397236585617065\n",
      "train loss 39.44913417642766\n",
      "train loss 34.34619863331317\n",
      "train loss 37.08103878157479\n",
      "train loss 39.394576356961174\n",
      "train loss 39.20759730954324\n",
      "train loss 36.71769517660141\n",
      "train loss 33.791454100027316\n",
      "train loss 35.361136337985165\n",
      "train loss 34.52940929169748\n",
      "train loss 32.553694433399606\n",
      "train loss 32.53429001081185\n",
      "train loss 33.135839397257016\n",
      "train loss 33.652663507931656\n",
      "train loss 32.9385822211441\n",
      "Epoch 18 avg Training loss: 32.012\n",
      "Epoch 18 avg Valid loss: 35.038\n",
      "Epoch 18 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 25.995849609375\n",
      "train loss 15.134271959463755\n",
      "train loss 24.399127732623707\n",
      "train loss 24.199144080281258\n",
      "train loss 27.807356119155887\n",
      "train loss 29.39723802529849\n",
      "train loss 31.71278514400606\n",
      "train loss 28.68635817037689\n",
      "train loss 29.138735465887123\n",
      "train loss 28.119218738182738\n",
      "train loss 31.04775690097435\n",
      "train loss 34.26747835108212\n",
      "train loss 32.99976840761841\n",
      "train loss 32.86310836221232\n",
      "train loss 32.351525563589284\n",
      "train loss 31.612592096391477\n",
      "Epoch 19 avg Training loss: 32.012\n",
      "Epoch 19 avg Valid loss: 35.039\n",
      "Epoch 19 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2069514989852905\n",
      "train loss 32.93010598421097\n",
      "train loss 30.17892844026739\n",
      "train loss 26.67275805771351\n",
      "train loss 27.597436575662528\n",
      "train loss 27.68976007058071\n",
      "train loss 32.21574511835653\n",
      "train loss 33.30727401706908\n",
      "train loss 31.733049270583372\n",
      "train loss 29.20587721855745\n",
      "train loss 32.76497098277598\n",
      "train loss 33.56048801967077\n",
      "train loss 33.05865052684409\n",
      "train loss 33.40237850853891\n",
      "train loss 32.57112884017782\n",
      "train loss 31.23898287980179\n",
      "Epoch 20 avg Training loss: 32.012\n",
      "Epoch 20 avg Valid loss: 35.038\n",
      "Epoch 20 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 50.39030075073242\n",
      "train loss 30.063919921716057\n",
      "train loss 32.83324049819599\n",
      "train loss 44.39380072802305\n",
      "train loss 39.328560102553595\n",
      "train loss 39.01052799591651\n",
      "train loss 35.518382687722486\n",
      "train loss 34.82922589447763\n",
      "train loss 33.38166309856787\n",
      "train loss 33.34401578229407\n",
      "train loss 33.83156007645178\n",
      "train loss 33.59622961069857\n",
      "train loss 32.63914064305728\n",
      "train loss 33.408378259702175\n",
      "train loss 33.65823923366171\n",
      "train loss 33.11224859011801\n",
      "Epoch 21 avg Training loss: 32.012\n",
      "Epoch 21 avg Valid loss: 35.038\n",
      "Epoch 21 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 9.601399421691895\n",
      "train loss 35.06159806251526\n",
      "train loss 29.924137321385473\n",
      "train loss 36.67016272991896\n",
      "train loss 39.36609483332861\n",
      "train loss 38.148633237068466\n",
      "train loss 38.75598041472897\n",
      "train loss 36.56198047267066\n",
      "train loss 36.42458015825691\n",
      "train loss 35.50871555701547\n",
      "train loss 34.2941098096324\n",
      "train loss 31.896744745118284\n",
      "train loss 30.298765630018522\n",
      "train loss 30.55452110731241\n",
      "train loss 30.94902009023748\n",
      "train loss 31.333679992901658\n",
      "Epoch 22 avg Training loss: 32.012\n",
      "Epoch 22 avg Valid loss: 35.038\n",
      "Epoch 22 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 4.404184341430664\n",
      "train loss 26.59909427165985\n",
      "train loss 33.887022126804695\n",
      "train loss 24.598810695111748\n",
      "train loss 25.579324580374212\n",
      "train loss 24.813806694287514\n",
      "train loss 25.327487930174794\n",
      "train loss 23.509899377822872\n",
      "train loss 29.29504402672372\n",
      "train loss 32.170675785645194\n",
      "train loss 32.80446246792288\n",
      "train loss 32.21817764214107\n",
      "train loss 34.49458135542322\n",
      "train loss 33.00865094228224\n",
      "train loss 32.77961987844654\n",
      "train loss 31.54421100334116\n",
      "Epoch 23 avg Training loss: 32.012\n",
      "Epoch 23 avg Valid loss: 35.038\n",
      "Epoch 23 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 50.390316009521484\n",
      "train loss 64.38801256815592\n",
      "train loss 47.84739886630665\n",
      "train loss 47.51793846487999\n",
      "train loss 42.85104640324911\n",
      "train loss 39.625370704210724\n",
      "train loss 36.511559836326114\n",
      "train loss 38.20598417851661\n",
      "train loss 38.35590097380849\n",
      "train loss 35.53475947483727\n",
      "train loss 34.646794220980496\n",
      "train loss 33.23202700274334\n",
      "train loss 32.9538337148604\n",
      "train loss 33.353944845271855\n",
      "train loss 33.28647336993421\n",
      "train loss 32.659677859983965\n",
      "Epoch 24 avg Training loss: 32.012\n",
      "Epoch 24 avg Valid loss: 35.038\n",
      "Epoch 24 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 1.2069493532180786\n",
      "train loss 8.603717625141144\n",
      "train loss 19.708984277465127\n",
      "train loss 27.59793584793806\n",
      "train loss 24.131962361789885\n",
      "train loss 27.397775462040535\n",
      "train loss 26.578737093556313\n",
      "train loss 25.29824310210016\n",
      "train loss 26.31976695467786\n",
      "train loss 27.284558817096375\n",
      "train loss 27.738716672448547\n",
      "train loss 29.49709260037967\n",
      "train loss 30.71160878314347\n",
      "train loss 29.027628445264064\n",
      "train loss 31.883959442796836\n",
      "train loss 31.82830910463082\n",
      "Epoch 25 avg Training loss: 32.012\n",
      "Epoch 25 avg Valid loss: 35.038\n",
      "Epoch 25 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 82.78475952148438\n",
      "train loss 20.533357878526054\n",
      "train loss 19.74610740488226\n",
      "train loss 25.24845895171165\n",
      "train loss 26.96966280823662\n",
      "train loss 29.213053098091713\n",
      "train loss 27.301137924194336\n",
      "train loss 26.564678576257492\n",
      "train loss 31.811367511749268\n",
      "train loss 33.100864923518635\n",
      "train loss 32.34961055540571\n",
      "train loss 32.98226078493254\n",
      "train loss 31.832827994080837\n",
      "train loss 31.263444066047665\n",
      "train loss 31.4897869774993\n",
      "train loss 31.544206496916313\n",
      "Epoch 26 avg Training loss: 32.012\n",
      "Epoch 26 avg Valid loss: 35.038\n",
      "Epoch 26 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 82.78475189208984\n",
      "train loss 32.93010799090068\n",
      "train loss 28.397869001735344\n",
      "train loss 33.07154844701291\n",
      "train loss 26.969661105246775\n",
      "train loss 28.120957512121937\n",
      "train loss 31.880886562408943\n",
      "train loss 35.12964718209373\n",
      "train loss 36.56163730272433\n",
      "train loss 35.56994554270869\n",
      "train loss 34.18446793509465\n",
      "train loss 34.13191311061383\n",
      "train loss 34.16024174260312\n",
      "train loss 33.887224289503976\n",
      "train loss 32.89229224265463\n",
      "train loss 31.544207356478058\n",
      "Epoch 27 avg Training loss: 32.012\n",
      "Epoch 27 avg Valid loss: 35.038\n",
      "Epoch 27 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 25.995866775512695\n",
      "train loss 28.263450702031456\n",
      "train loss 21.853681726889178\n",
      "train loss 28.697416000068188\n",
      "train loss 29.425747479711266\n",
      "train loss 28.19734945205542\n",
      "train loss 28.28115882796626\n",
      "train loss 31.085438049501843\n",
      "train loss 31.79145075344458\n",
      "train loss 31.18782296906347\n",
      "train loss 31.573033045319946\n",
      "train loss 30.29689532944134\n",
      "train loss 31.314706374387274\n",
      "train loss 30.560499769268613\n",
      "train loss 31.985329327448987\n",
      "train loss 31.11796563236336\n",
      "Epoch 28 avg Training loss: 32.012\n",
      "Epoch 28 avg Valid loss: 35.038\n",
      "Epoch 28 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2069493532180786\n",
      "train loss 35.1296443939209\n",
      "train loss 37.0137789032676\n",
      "train loss 35.59532919526101\n",
      "train loss 37.690029189700184\n",
      "train loss 38.22554931732326\n",
      "train loss 34.31842856637894\n",
      "train loss 36.51737666461203\n",
      "train loss 32.74747405691844\n",
      "train loss 35.073929115481995\n",
      "train loss 35.94062173366545\n",
      "train loss 34.85299345425195\n",
      "train loss 34.5532275418766\n",
      "train loss 34.59593457706045\n",
      "train loss 33.94545946490596\n",
      "train loss 31.98620120788874\n",
      "Epoch 29 avg Training loss: 32.012\n",
      "Epoch 29 avg Valid loss: 35.038\n",
      "Epoch 29 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 37.193084716796875\n",
      "train loss 28.063905715942383\n",
      "train loss 40.35822691700675\n",
      "train loss 33.92102549225092\n",
      "train loss 34.05352410248348\n",
      "train loss 33.227155955938194\n",
      "train loss 31.312966804350573\n",
      "train loss 35.2403741909398\n",
      "train loss 35.264145380113185\n",
      "train loss 34.309077208456785\n",
      "train loss 32.78871715770048\n",
      "train loss 31.339651712349486\n",
      "train loss 32.003229352294426\n",
      "train loss 31.378680523597833\n",
      "train loss 31.303912763864222\n",
      "train loss 30.633901216481867\n",
      "Epoch 30 avg Training loss: 32.012\n",
      "Epoch 30 avg Valid loss: 35.038\n",
      "Epoch 30 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2069505453109741\n",
      "train loss 25.465294082959492\n",
      "train loss 28.7973659472032\n",
      "train loss 28.322412736713886\n",
      "train loss 31.215824229376658\n",
      "train loss 29.90482610005599\n",
      "train loss 36.17622923851013\n",
      "train loss 34.45164011253251\n",
      "train loss 36.93196523189545\n",
      "train loss 36.29990008602971\n",
      "train loss 37.65810974205241\n",
      "train loss 36.80270036629267\n",
      "train loss 35.38606515282489\n",
      "train loss 34.28095709555076\n",
      "train loss 33.39339150509363\n",
      "train loss 31.4441379543982\n",
      "Epoch 31 avg Training loss: 32.012\n",
      "Epoch 31 avg Valid loss: 35.038\n",
      "Epoch 31 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.995851516723633\n",
      "train loss 31.662526210149128\n",
      "train loss 18.400396596301686\n",
      "train loss 18.925364039838314\n",
      "train loss 23.02799328168233\n",
      "train loss 24.183243852395275\n",
      "train loss 28.978109475105036\n",
      "train loss 31.796700563695694\n",
      "train loss 30.08480777391573\n",
      "train loss 31.1966966105544\n",
      "train loss 33.02373809206719\n",
      "train loss 34.18171479446547\n",
      "train loss 34.205960854155116\n",
      "train loss 32.7721985668847\n",
      "train loss 32.1825103944456\n",
      "train loss 32.233424690208935\n",
      "Epoch 32 avg Training loss: 32.012\n",
      "Epoch 32 avg Valid loss: 35.038\n",
      "Epoch 32 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 82.78475189208984\n",
      "train loss 35.73057442903519\n",
      "train loss 37.414541883902125\n",
      "train loss 32.671895198524005\n",
      "train loss 34.68196505024321\n",
      "train loss 32.35066002607346\n",
      "train loss 32.95131964452806\n",
      "train loss 34.09600942333541\n",
      "train loss 32.15283253425506\n",
      "train loss 30.188425761202115\n",
      "train loss 29.949992369203013\n",
      "train loss 32.63216252199241\n",
      "train loss 33.84530653132767\n",
      "train loss 32.9418541915489\n",
      "train loss 31.10117260838898\n",
      "train loss 33.15429543194017\n",
      "Epoch 33 avg Training loss: 32.012\n",
      "Epoch 33 avg Valid loss: 35.038\n",
      "Epoch 33 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2069491147994995\n",
      "train loss 18.13426947593689\n",
      "train loss 30.797362067482688\n",
      "train loss 35.471195586025715\n",
      "train loss 34.07230334622519\n",
      "train loss 35.934095992491784\n",
      "train loss 35.944056372488696\n",
      "train loss 35.617916782697044\n",
      "train loss 34.17172920703889\n",
      "train loss 34.309073194213546\n",
      "train loss 31.996664944817056\n",
      "train loss 31.846691521150742\n",
      "train loss 33.07827125416429\n",
      "train loss 30.85754848610273\n",
      "train loss 30.532233919895887\n",
      "train loss 30.370739438031862\n",
      "Epoch 34 avg Training loss: 32.012\n",
      "Epoch 34 avg Valid loss: 35.038\n",
      "Epoch 34 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.99585723876953\n",
      "train loss 11.06853159268697\n",
      "train loss 28.397869586944584\n",
      "train loss 32.046890914440155\n",
      "train loss 31.101801662218\n",
      "train loss 28.613369854596943\n",
      "train loss 32.47425493501848\n",
      "train loss 33.35225429137548\n",
      "train loss 32.777353900234885\n",
      "train loss 32.84886965285178\n",
      "train loss 29.93479301415239\n",
      "train loss 31.44704133272172\n",
      "train loss 31.826361101181792\n",
      "train loss 30.912180902379944\n",
      "train loss 31.732001272725398\n",
      "train loss 31.04957895686753\n",
      "Epoch 35 avg Training loss: 32.012\n",
      "Epoch 35 avg Valid loss: 35.038\n",
      "Epoch 35 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.995851516723633\n",
      "train loss 16.667146066824593\n",
      "train loss 18.036757154898208\n",
      "train loss 24.523974321782593\n",
      "train loss 26.112516125043236\n",
      "train loss 30.05867159825105\n",
      "train loss 26.411083002244276\n",
      "train loss 28.22000169091755\n",
      "train loss 28.183045741988394\n",
      "train loss 28.571455276530727\n",
      "train loss 28.138880002732375\n",
      "train loss 27.690742330891748\n",
      "train loss 28.17476785378378\n",
      "train loss 29.264075777747415\n",
      "train loss 30.74628262452676\n",
      "train loss 30.476005918101258\n",
      "Epoch 36 avg Training loss: 32.012\n",
      "Epoch 36 avg Valid loss: 35.038\n",
      "Epoch 36 Valid accuracy: 20.0% (2 of 10 right)\n",
      "\n",
      "train loss 1.2069560289382935\n",
      "train loss 34.46298251549403\n",
      "train loss 31.85115403478796\n",
      "train loss 33.54602575302124\n",
      "train loss 38.0522005217416\n",
      "train loss 39.14862943154115\n",
      "train loss 37.36296557611035\n",
      "train loss 38.184045020076965\n",
      "train loss 35.94706942976975\n",
      "train loss 36.09138134769771\n",
      "train loss 34.52940100782057\n",
      "train loss 34.67466955099786\n",
      "train loss 33.70769013342309\n",
      "train loss 34.06883047205029\n",
      "train loss 33.2132604189322\n",
      "train loss 32.91226110646599\n",
      "Epoch 37 avg Training loss: 32.012\n",
      "Epoch 37 avg Valid loss: 35.038\n",
      "Epoch 37 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 25.9958553314209\n",
      "train loss 50.59215074777603\n",
      "train loss 40.35822703621604\n",
      "train loss 39.4949850961566\n",
      "train loss 38.680641259465894\n",
      "train loss 33.68869366554113\n",
      "train loss 34.71870169716496\n",
      "train loss 35.97355348865191\n",
      "train loss 36.40533833678176\n",
      "train loss 33.43981333400892\n",
      "train loss 31.85554630616132\n",
      "train loss 32.58211189508439\n",
      "train loss 31.70814710757772\n",
      "train loss 31.96639202760928\n",
      "train loss 33.292216646839194\n",
      "train loss 33.15430045441577\n",
      "Epoch 38 avg Training loss: 32.012\n",
      "Epoch 38 avg Valid loss: 35.038\n",
      "Epoch 38 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 4.40420389175415\n",
      "train loss 53.79176966349284\n",
      "train loss 42.030517751520335\n",
      "train loss 32.37177961319685\n",
      "train loss 38.94762353102366\n",
      "train loss 36.96501911603487\n",
      "train loss 36.576534455822355\n",
      "train loss 37.57335475749439\n",
      "train loss 33.577113954032335\n",
      "train loss 33.222749735998065\n",
      "train loss 33.0240339344623\n",
      "train loss 32.13972163413251\n",
      "train loss 31.059349476313976\n",
      "train loss 31.390860478083287\n",
      "train loss 30.21683750689869\n",
      "train loss 31.402079939842217\n",
      "Epoch 39 avg Training loss: 32.012\n",
      "Epoch 39 avg Valid loss: 35.037\n",
      "Epoch 39 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 4.404173374176025\n",
      "train loss 37.26112914085388\n",
      "train loss 38.249388272112064\n",
      "train loss 39.59446582943201\n",
      "train loss 37.423763683864046\n",
      "train loss 37.103118437987106\n",
      "train loss 36.614671630244096\n",
      "train loss 36.317844923999566\n",
      "train loss 34.91306236895119\n",
      "train loss 32.64005613067875\n",
      "train loss 30.953859511543712\n",
      "train loss 32.09669660244668\n",
      "train loss 30.96743740214675\n",
      "train loss 29.79715698596202\n",
      "train loss 31.495344203962397\n",
      "train loss 32.475458109065094\n",
      "Epoch 40 avg Training loss: 32.012\n",
      "Epoch 40 avg Valid loss: 35.038\n",
      "Epoch 40 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 4.404174327850342\n",
      "train loss 10.535657505194346\n",
      "train loss 30.79736343297091\n",
      "train loss 30.072413250803944\n",
      "train loss 33.863047293254304\n",
      "train loss 34.10418513187995\n",
      "train loss 35.64782305686704\n",
      "train loss 34.12964786423577\n",
      "train loss 33.71346659776642\n",
      "train loss 30.727613819682087\n",
      "train loss 29.573846094748557\n",
      "train loss 29.297388049108648\n",
      "train loss 30.206870600825457\n",
      "train loss 32.142020873951196\n",
      "train loss 30.864512426752448\n",
      "train loss 32.23342380555053\n",
      "Epoch 41 avg Training loss: 32.012\n",
      "Epoch 41 avg Valid loss: 35.038\n",
      "Epoch 41 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.995847702026367\n",
      "train loss 40.660203774770096\n",
      "train loss 34.904941786419265\n",
      "train loss 30.27223864942789\n",
      "train loss 26.01727702504113\n",
      "train loss 27.120955348014835\n",
      "train loss 26.48832157734902\n",
      "train loss 26.94222191638417\n",
      "train loss 25.607975607965056\n",
      "train loss 25.85895219833955\n",
      "train loss 25.817689154662343\n",
      "train loss 27.697535112500194\n",
      "train loss 28.895621164900362\n",
      "train loss 29.797153247125223\n",
      "train loss 29.631020545959473\n",
      "train loss 31.402062279613396\n",
      "Epoch 42 avg Training loss: 32.012\n",
      "Epoch 42 avg Valid loss: 35.037\n",
      "Epoch 42 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 16.79862403869629\n",
      "train loss 26.7305699189504\n",
      "train loss 36.57716183228926\n",
      "train loss 37.69480800628662\n",
      "train loss 38.52773130507696\n",
      "train loss 34.85717648267746\n",
      "train loss 33.75095886953416\n",
      "train loss 36.11792068348991\n",
      "train loss 32.601475125405855\n",
      "train loss 34.569946156895696\n",
      "train loss 33.30598213392147\n",
      "train loss 31.589402422308936\n",
      "train loss 30.744393082915774\n",
      "train loss 32.45102747281394\n",
      "train loss 33.74272109253308\n",
      "train loss 33.59091678261759\n",
      "Epoch 43 avg Training loss: 32.012\n",
      "Epoch 43 avg Valid loss: 35.038\n",
      "Epoch 43 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 25.995849609375\n",
      "train loss 44.859739879767105\n",
      "train loss 35.449132193218574\n",
      "train loss 35.1455015912652\n",
      "train loss 41.422436379251025\n",
      "train loss 44.60856357446084\n",
      "train loss 42.04540104250754\n",
      "train loss 37.839366694291435\n",
      "train loss 35.644425072321084\n",
      "train loss 36.039024575896896\n",
      "train loss 34.78016194409017\n",
      "train loss 36.60978762805463\n",
      "train loss 36.31679649235774\n",
      "train loss 34.117271903789415\n",
      "train loss 33.43841605455104\n",
      "train loss 33.54884684870119\n",
      "Epoch 44 avg Training loss: 32.012\n",
      "Epoch 44 avg Valid loss: 35.038\n",
      "Epoch 44 Valid accuracy: 10.0% (1 of 10 right)\n",
      "\n",
      "train loss 1.2069587707519531\n",
      "train loss 6.404177765051523\n",
      "train loss 23.345349821177393\n",
      "train loss 21.274849086999893\n",
      "train loss 31.36874285198393\n",
      "train loss 29.25910531557523\n",
      "train loss 30.371573390499233\n",
      "train loss 32.630038648843765\n",
      "train loss 35.44965032542624\n",
      "train loss 32.970432506955184\n",
      "train loss 36.003589160302106\n",
      "train loss 36.29565615952015\n",
      "train loss 33.629186813948586\n",
      "train loss 31.972578449682754\n",
      "train loss 32.2164315690457\n",
      "train loss 32.09146649900236\n",
      "Epoch 45 avg Training loss: 32.012\n",
      "Epoch 45 avg Valid loss: 35.038\n",
      "Epoch 45 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 4.404173374176025\n",
      "train loss 13.667141437530518\n",
      "train loss 22.68978773463856\n",
      "train loss 31.472068764269352\n",
      "train loss 28.987784186999\n",
      "train loss 36.3187194283192\n",
      "train loss 36.627845137350015\n",
      "train loss 36.117923895517976\n",
      "train loss 33.82065237731467\n",
      "train loss 33.85714705612348\n",
      "train loss 34.41175908200881\n",
      "train loss 35.738563414130894\n",
      "train loss 35.63519880029022\n",
      "train loss 35.26858148069092\n",
      "train loss 34.50309154517213\n",
      "train loss 32.57553125212066\n",
      "Epoch 46 avg Training loss: 32.012\n",
      "Epoch 46 avg Valid loss: 35.038\n",
      "Epoch 46 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 25.9958438873291\n",
      "train loss 24.664824903011322\n",
      "train loss 25.37993457100608\n",
      "train loss 27.747581034898758\n",
      "train loss 27.635660381544206\n",
      "train loss 26.76721312449529\n",
      "train loss 32.925417161756954\n",
      "train loss 34.895693646536934\n",
      "train loss 32.23046800566882\n",
      "train loss 34.36112559360006\n",
      "train loss 31.94170785651486\n",
      "train loss 31.00388317448751\n",
      "train loss 31.426221570030577\n",
      "train loss 32.40258332996657\n",
      "train loss 34.12002832620915\n",
      "train loss 32.407070559890634\n",
      "Epoch 47 avg Training loss: 32.012\n",
      "Epoch 47 avg Valid loss: 35.038\n",
      "Epoch 47 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 1.2069529294967651\n",
      "train loss 20.00047779083252\n",
      "train loss 37.70519841801036\n",
      "train loss 30.297761566936966\n",
      "train loss 31.59743800049736\n",
      "train loss 30.766683583076176\n",
      "train loss 28.60418272787524\n",
      "train loss 31.852254675494294\n",
      "train loss 31.46990164896336\n",
      "train loss 28.97133259151292\n",
      "train loss 27.77019546312443\n",
      "train loss 28.811722227505268\n",
      "train loss 29.813654684629586\n",
      "train loss 31.378678217078694\n",
      "train loss 31.991076842160282\n",
      "train loss 32.04402231856396\n",
      "Epoch 48 avg Training loss: 32.012\n",
      "Epoch 48 avg Valid loss: 35.038\n",
      "Epoch 48 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 4.404173374176025\n",
      "train loss 37.19538599252701\n",
      "train loss 36.3953444740989\n",
      "train loss 33.22119522839785\n",
      "train loss 33.6725671745482\n",
      "train loss 32.16593260948475\n",
      "train loss 35.4538232972545\n",
      "train loss 36.83975317080815\n",
      "train loss 35.224981488251096\n",
      "train loss 34.44808249629062\n",
      "train loss 34.043070765102605\n",
      "train loss 33.56048146315983\n",
      "train loss 32.927496910095215\n",
      "train loss 33.281160110777066\n",
      "train loss 32.50922889776632\n",
      "train loss 31.93356778747157\n",
      "Epoch 49 avg Training loss: 32.012\n",
      "Epoch 49 avg Valid loss: 35.038\n",
      "Epoch 49 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n",
      "train loss 65.5875244140625\n",
      "train loss 43.79400326808294\n",
      "train loss 42.575904596935615\n",
      "train loss 32.32154626399278\n",
      "train loss 29.349950994764047\n",
      "train loss 31.28944035676809\n",
      "train loss 34.435188158865884\n",
      "train loss 31.830341143740533\n",
      "train loss 33.138059677147275\n",
      "train loss 33.648628784262606\n",
      "train loss 33.10244111687528\n",
      "train loss 32.211128183773575\n",
      "train loss 31.77394679335296\n",
      "train loss 32.226953217477494\n",
      "train loss 32.278322889771246\n",
      "train loss 32.780682217133666\n",
      "Epoch 50 avg Training loss: 32.012\n",
      "Epoch 50 avg Valid loss: 35.038\n",
      "Epoch 50 Valid accuracy: 0.0% (0 of 10 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(params['n_epochs']):\n",
    "    train_loss = train_one_epoch(epoch, model, loss_fn, optimizer, train_loader)\n",
    "    train_losses+= [train_loss]\n",
    "    valid_loss, accuracy, correct, total = test_one_epoch(epoch, model, loss_fn, valid_loader, len_val)\n",
    "    valid_losses+=[valid_loss]\n",
    "    print('Epoch {} avg Valid loss: {:.3f}'.format(epoch+1, valid_loss))\n",
    "    print('Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n'.format(epoch+1, accuracy, correct, total))\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_fn,\n",
    "            }, 'checkpoint.tar')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e920b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 28.318\n",
      "Test accuracy: 30.0% (3 of 10 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "checkpoint = torch.load('checkpoint.tar')\n",
    "loaded_model = Net(params['num_classes'])\n",
    "loaded_model.to(params[\"device\"])\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "loaded_criterion = checkpoint['loss']\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "last_epoch = checkpoint['epoch']+1\n",
    "\n",
    "test_loss, accuracy, correct, total = test_one_epoch(None, loaded_model, loaded_criterion, test_loader, len_val)\n",
    "\n",
    "print('Test loss: {:.3f}'.format(test_loss))\n",
    "print('Test accuracy: {:.1%} ({} of {} right)\\n'.format(accuracy, correct, total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d2f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66cfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
