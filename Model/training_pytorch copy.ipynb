{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6dbd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import timm \n",
    "import torch\n",
    "\n",
    "# I'm adding this in\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "METADATA_SUBSET_PATH = \"/Users/franceskoback/Documents/xray_test/metadata_100subset_df.csv\"\n",
    "\n",
    "def get_manufacturer_labels(encoder, target_variable = \"(0008, 0070) Manufacturer\"):\n",
    "    df = pd.read_csv(METADATA_SUBSET_PATH)\n",
    "    df[\"id\"] = df[\"id\"].astype(\"str\").str.zfill(8)\n",
    "    df[\"code\"] = encoder.fit_transform(df[target_variable])\n",
    "    \n",
    "    return {row[\"id\"]: row[\"code\"] for i, row in df.iterrows()}\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #self.img_dir = \"/Users/franceskoback/Documents/research/pytorch_1/imagezz\"\n",
    "        self.img_dir = \"/Users/franceskoback/Documents/xray_test/xray_subsets\"\n",
    "\n",
    "        self.images = glob.glob(os.path.join(self.img_dir, \"*.npy\")) \n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.label_map = get_manufacturer_labels(self.le)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.fromarray(np.load(img_path)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "        xray_id = os.path.basename(img_path).replace(\".npy\", \"\")\n",
    "        \n",
    "        return {\"image\": image, \"label\": self.label_map[xray_id]}\n",
    "\n",
    "def train_val_dataset(dataset, val_split=0.25):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7225df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "Training length 75\n",
      "Validation length 25\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset()\n",
    "datasets = train_val_dataset(dataset)\n",
    "print(len(datasets['train'].dataset)) #6\n",
    "#datasets['train'].dataset, batch_size=params[\"batch_size\"], shuffle=True\n",
    "train_loader = DataLoader(\n",
    "    datasets['train'].dataset, batch_size=3, shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    datasets['val'].dataset, batch_size=3, shuffle=True\n",
    ")\n",
    "print(len(train_loader.dataset)) #6 \n",
    "len_train=len(datasets['train'])\n",
    "len_val= len(datasets['val'])\n",
    "print(\"Training length\", len(datasets['train']))\n",
    "print(\"Validation length\", len(datasets['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80723e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def Net(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    #model=timm.create_model(model,pretrained= True)\n",
    "    #model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    #model= efn.EfficientNetB0(weights='imagenet')\n",
    "    # Freeze parameters so we don't backprop through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                              ('fc1', nn.Linear(2048, 1024)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('fc2', nn.Linear(1024, 256)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('fc3', nn.Linear(256, num_classes)),\n",
    "                              ('output', nn.LogSoftmax(dim=1))\n",
    "                              ]))\n",
    "\n",
    "    model.fc = classifier\n",
    "    return model\n",
    "\n",
    "params = {\n",
    "    \"model\": \"resnet50\",\n",
    "    #\"device\": \"cuda\",\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 3, #64\n",
    "    \"num_workers\": 1, #20\n",
    "    \"n_epochs\": 50, #100\n",
    "    \"image_size\": 224, \n",
    "    \"in_channels\": 3, #3\n",
    "    \"num_classes\": 3, #12\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "model = Net(params['num_classes'])\n",
    "model.to(params[\"device\"])\n",
    "#loss_fn = nn.NLLLoss() # we want MSE loss i think \n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dee2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device = \"cpu\"):\n",
    "    #put model in training state\n",
    "    model.train()\n",
    "    #i=0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "\n",
    "    for batch_idx, img_dicts in enumerate(train_loader,0):  #used to be enumerate(train_loader)\n",
    "        inputs = img_dicts[\"image\"] #ORIGINAL ONE\n",
    "        labels = img_dicts[\"label\"]  # ORIGINAL ONE\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        #print(inputs.shape, labels.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() # do we need this or not? sets all grads to None \n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "         #   print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            #running_loss=0\n",
    "          #  i=i+1\n",
    "\n",
    "        \n",
    "        \n",
    "        #\n",
    "    \n",
    "        train_loss+= ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "        if batch_idx%5==0:\n",
    "            print('train loss', train_loss)\n",
    "    \n",
    "    #print('Epoch {} avg Training loss: {:.3f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "    return model, train_loss\n",
    "\n",
    "def test_one_epoch(epoch, model, loss_fn, loader, len_val, device = \"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    #pbar = tqdm(enumerate(test_loader), total = len(test_loader))\n",
    "    running_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    #for step, (imgs, labels) in pbar:\n",
    "    for batch_idx, img_dicts in enumerate(loader,0):    \n",
    "        inputs = img_dicts[\"image\"] #ORIGINAL ONE\n",
    "        labels = img_dicts[\"label\"]  # ORIGINAL ONE\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        \n",
    "        log_preds = model(inputs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "        \n",
    "        preds = torch.exp(log_preds)\n",
    "        running_loss+=((1 / (batch_idx + 1)) * (loss.data.item() - running_loss))\n",
    "        \n",
    "        #calculate accuracy\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "        actual_labels+= list(labels.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    \n",
    "    accuracy = ((np.array(pred_labels)==np.array(actual_labels)).sum())/len_val #size of test set\n",
    "    correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "    total = len_val\n",
    "    \n",
    "    \n",
    "    return running_loss, accuracy, correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f203fbb",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d563e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 45.04386901855469\n",
      "train loss 35.91239229838053\n",
      "train loss 25.223380608992144\n",
      "train loss 25.93820208311081\n",
      "train loss 26.949111121041433\n",
      "train loss 30.232530515927536\n",
      "train loss 34.17260255736689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franceskoback/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg Valid loss: 31.362\n",
      "Epoch 1 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 36.46467590332031\n",
      "train loss 34.94554154078166\n",
      "train loss 33.49651033228094\n",
      "train loss 33.08366608619691\n",
      "train loss 31.852205208369668\n",
      "train loss 29.74642079151594\n",
      "train loss 32.368195922144\n",
      "Epoch 2 avg Valid loss: 32.585\n",
      "Epoch 2 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 3.2914562225341797\n",
      "train loss 26.406837463378906\n",
      "train loss 23.64210785518993\n",
      "train loss 21.4831165522337\n",
      "train loss 28.852644182386857\n",
      "train loss 30.587758972094615\n",
      "train loss 31.615715788256743\n",
      "Epoch 3 avg Valid loss: 33.084\n",
      "Epoch 3 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 3.262333631515503\n",
      "train loss 34.5616055727005\n",
      "train loss 33.910685690966524\n",
      "train loss 31.347480580210686\n",
      "train loss 30.23035387765794\n",
      "train loss 31.999841121526867\n",
      "train loss 31.74843469742806\n",
      "Epoch 4 avg Valid loss: 31.396\n",
      "Epoch 4 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 52.93706130981445\n",
      "train loss 41.68382581075033\n",
      "train loss 35.148681987415664\n",
      "train loss 30.54660212993622\n",
      "train loss 26.90729570388794\n",
      "train loss 30.261367889551018\n",
      "train loss 32.99289452645086\n",
      "Epoch 5 avg Valid loss: 31.468\n",
      "Epoch 5 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 18.46961212158203\n",
      "train loss 30.781605084737144\n",
      "train loss 34.122623963789515\n",
      "train loss 38.57393980026246\n",
      "train loss 34.17208432015919\n",
      "train loss 34.63625758427841\n",
      "train loss 31.161595444525457\n",
      "Epoch 6 avg Valid loss: 31.397\n",
      "Epoch 6 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 31.13066291809082\n",
      "train loss 24.218653837839764\n",
      "train loss 29.564354549754746\n",
      "train loss 32.80296456813812\n",
      "train loss 31.57624998546782\n",
      "train loss 31.78333029380212\n",
      "train loss 31.513983880319905\n",
      "Epoch 7 avg Valid loss: 31.373\n",
      "Epoch 7 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 16.99146270751953\n",
      "train loss 35.52097511291504\n",
      "train loss 32.673577395352446\n",
      "train loss 35.32839846611022\n",
      "train loss 33.883134932745065\n",
      "train loss 34.50616970429053\n",
      "train loss 31.85410925649827\n",
      "Epoch 8 avg Valid loss: 31.913\n",
      "Epoch 8 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 37.684852600097656\n",
      "train loss 25.038331826527912\n",
      "train loss 30.30273413658142\n",
      "train loss 34.25327284634113\n",
      "train loss 30.69668356577555\n",
      "train loss 32.22193626257089\n",
      "train loss 33.65883828747657\n",
      "Epoch 9 avg Valid loss: 33.022\n",
      "Epoch 9 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 28.741756439208984\n",
      "train loss 36.474900245666504\n",
      "train loss 45.35906965082342\n",
      "train loss 39.61175864934921\n",
      "train loss 32.23606286730085\n",
      "train loss 31.434086029346172\n",
      "train loss 31.495805248137447\n",
      "Epoch 10 avg Valid loss: 32.950\n",
      "Epoch 10 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 20.511764526367188\n",
      "train loss 25.546594421068825\n",
      "train loss 33.08530640602112\n",
      "train loss 33.86825339496136\n",
      "train loss 34.4999564148131\n",
      "train loss 33.16575120962584\n",
      "train loss 32.765126282168985\n",
      "Epoch 11 avg Valid loss: 31.833\n",
      "Epoch 11 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 32.17751693725586\n",
      "train loss 25.379900534947712\n",
      "train loss 27.210764754902232\n",
      "train loss 27.022563964128494\n",
      "train loss 27.277384326571507\n",
      "train loss 31.834627499947178\n",
      "train loss 31.409932171144792\n",
      "Epoch 12 avg Valid loss: 31.404\n",
      "Epoch 12 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 36.78974151611328\n",
      "train loss 30.909737030665077\n",
      "train loss 32.568725455891006\n",
      "train loss 28.977080911397938\n",
      "train loss 29.83410860243298\n",
      "train loss 30.292344698539146\n",
      "train loss 31.4462528997852\n",
      "Epoch 13 avg Valid loss: 32.955\n",
      "Epoch 13 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 22.9071102142334\n",
      "train loss 29.247024377187092\n",
      "train loss 26.439542163502086\n",
      "train loss 26.25714868307114\n",
      "train loss 32.32487483251663\n",
      "train loss 34.07025656333337\n",
      "train loss 32.47543508775774\n",
      "Epoch 14 avg Valid loss: 31.451\n",
      "Epoch 14 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 10.484108924865723\n",
      "train loss 28.911906401316323\n",
      "train loss 31.569196267561477\n",
      "train loss 27.271685302257534\n",
      "train loss 28.134816941760832\n",
      "train loss 28.599117095653824\n",
      "train loss 29.112340588723463\n",
      "Epoch 15 avg Valid loss: 31.852\n",
      "Epoch 15 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 30.387054443359375\n",
      "train loss 32.03710110982259\n",
      "train loss 34.73130588098006\n",
      "train loss 32.6246747225523\n",
      "train loss 30.464083410444715\n",
      "train loss 31.408525943756104\n",
      "train loss 32.14759109866234\n",
      "Epoch 16 avg Valid loss: 31.466\n",
      "Epoch 16 Valid accuracy: 52.0% (13 of 25 right)\n",
      "\n",
      "train loss 28.842079162597656\n",
      "train loss 36.23890527089437\n",
      "train loss 35.21149201826616\n",
      "train loss 36.99769547581673\n",
      "train loss 34.06423203150431\n",
      "train loss 34.042978965319115\n",
      "train loss 33.128264688676396\n",
      "Epoch 17 avg Valid loss: 31.365\n",
      "Epoch 17 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 18.789520263671875\n",
      "train loss 37.92121569315592\n",
      "train loss 40.92409376664595\n",
      "train loss 40.7641167640686\n",
      "train loss 35.57875747907729\n",
      "train loss 34.513200879096985\n",
      "train loss 32.72463774681091\n",
      "Epoch 18 avg Valid loss: 31.364\n",
      "Epoch 18 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 55.65972900390625\n",
      "train loss 32.1270895799001\n",
      "train loss 32.25410470095547\n",
      "train loss 34.62083786725997\n",
      "train loss 33.62777655465262\n",
      "train loss 35.857509658886826\n",
      "train loss 32.70039028506124\n",
      "Epoch 19 avg Valid loss: 31.829\n",
      "Epoch 19 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 12.164463996887207\n",
      "train loss 36.59433341026306\n",
      "train loss 31.836938641288064\n",
      "train loss 33.44540759921073\n",
      "train loss 34.06429006939842\n",
      "train loss 32.07677685297452\n",
      "train loss 31.03995410857662\n",
      "Epoch 20 avg Valid loss: 32.334\n",
      "Epoch 20 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 22.5906982421875\n",
      "train loss 39.093912839889526\n",
      "train loss 34.6636268008839\n",
      "train loss 35.11593368649483\n",
      "train loss 33.197469643184114\n",
      "train loss 31.82465221331669\n",
      "train loss 31.673367638741766\n",
      "Epoch 21 avg Valid loss: 31.498\n",
      "Epoch 21 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 33.77766418457031\n",
      "train loss 41.5078550974528\n",
      "train loss 36.642240741036154\n",
      "train loss 33.90309837460518\n",
      "train loss 34.12611198425293\n",
      "train loss 33.53590202331543\n",
      "train loss 32.228866054165756\n",
      "Epoch 22 avg Valid loss: 32.293\n",
      "Epoch 22 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 11.58694076538086\n",
      "train loss 30.643285433451336\n",
      "train loss 37.35399601676247\n",
      "train loss 39.50036233663559\n",
      "train loss 34.57779135022845\n",
      "train loss 33.815342206221366\n",
      "train loss 31.777030198804795\n",
      "Epoch 23 avg Valid loss: 31.831\n",
      "Epoch 23 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 36.75613784790039\n",
      "train loss 32.176368395487465\n",
      "train loss 37.24908494949341\n",
      "train loss 36.72630020976067\n",
      "train loss 33.98883040746053\n",
      "train loss 33.30723360868601\n",
      "train loss 31.696739027577067\n",
      "Epoch 24 avg Valid loss: 32.308\n",
      "Epoch 24 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 44.885459899902344\n",
      "train loss 35.75525077184041\n",
      "train loss 34.69953489303588\n",
      "train loss 34.355161607265465\n",
      "train loss 32.64279507455372\n",
      "train loss 33.467526866839485\n",
      "train loss 33.45797781021364\n",
      "Epoch 25 avg Valid loss: 31.355\n",
      "Epoch 25 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 6.124677658081055\n",
      "train loss 33.15449301401774\n",
      "train loss 33.86997335607355\n",
      "train loss 32.91961692273616\n",
      "train loss 30.2302991208576\n",
      "train loss 32.45970479341654\n",
      "train loss 31.63548219588496\n",
      "Epoch 26 avg Valid loss: 31.828\n",
      "Epoch 26 Valid accuracy: 80.0% (20 of 25 right)\n",
      "\n",
      "train loss 17.714828491210938\n",
      "train loss 30.090930461883545\n",
      "train loss 28.716387358578768\n",
      "train loss 30.867083817720413\n",
      "train loss 33.10758747373308\n",
      "train loss 31.92791548142066\n",
      "train loss 32.910513339504114\n",
      "Epoch 27 avg Valid loss: 31.506\n",
      "Epoch 27 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 12.278556823730469\n",
      "train loss 19.603410879770912\n",
      "train loss 23.518832813609727\n",
      "train loss 28.2959286570549\n",
      "train loss 28.715377432959418\n",
      "train loss 28.35885165287898\n",
      "train loss 30.141891356437434\n",
      "Epoch 28 avg Valid loss: 33.317\n",
      "Epoch 28 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 37.70376968383789\n",
      "train loss 34.74631555875142\n",
      "train loss 32.82061182368886\n",
      "train loss 32.93902003765106\n",
      "train loss 35.028159550258096\n",
      "train loss 32.18706119977511\n",
      "train loss 33.28779020617085\n",
      "Epoch 29 avg Valid loss: 31.428\n",
      "Epoch 29 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 39.31861114501953\n",
      "train loss 30.13456126054128\n",
      "train loss 36.55576760118658\n",
      "train loss 36.191036120057106\n",
      "train loss 32.297585782550634\n",
      "train loss 33.12009853583116\n",
      "train loss 32.38242061676518\n",
      "Epoch 30 avg Valid loss: 31.415\n",
      "Epoch 30 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 34.61970138549805\n",
      "train loss 34.356539249420166\n",
      "train loss 33.67575740814209\n",
      "train loss 37.20423477888108\n",
      "train loss 36.4243792125157\n",
      "train loss 34.77462588823759\n",
      "train loss 33.19247179646646\n",
      "Epoch 31 avg Valid loss: 32.910\n",
      "Epoch 31 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 55.74788284301758\n",
      "train loss 44.77126471201579\n",
      "train loss 36.090284130790025\n",
      "train loss 31.97901204228402\n",
      "train loss 29.847237246377134\n",
      "train loss 31.999500916554386\n",
      "train loss 31.78986833941553\n",
      "Epoch 32 avg Valid loss: 31.403\n",
      "Epoch 32 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 10.58743667602539\n",
      "train loss 21.46192820866903\n",
      "train loss 25.996379375457767\n",
      "train loss 30.246141970157623\n",
      "train loss 31.75824776149931\n",
      "train loss 31.468051561942463\n",
      "train loss 32.11755352635537\n",
      "Epoch 33 avg Valid loss: 31.835\n",
      "Epoch 33 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 44.85791015625\n",
      "train loss 37.39327907562256\n",
      "train loss 35.462034312161535\n",
      "train loss 35.99630671739579\n",
      "train loss 35.88067222776868\n",
      "train loss 33.89625400763292\n",
      "train loss 32.387750887101696\n",
      "Epoch 34 avg Valid loss: 31.661\n",
      "Epoch 34 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 21.46302032470703\n",
      "train loss 39.44159873326619\n",
      "train loss 36.750374967401676\n",
      "train loss 36.62920561432839\n",
      "train loss 32.13245188622248\n",
      "train loss 32.844252888972946\n",
      "train loss 31.871811043831606\n",
      "Epoch 35 avg Valid loss: 31.920\n",
      "Epoch 35 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 38.19614791870117\n",
      "train loss 32.617118279139206\n",
      "train loss 35.410208138552576\n",
      "train loss 31.63429364562034\n",
      "train loss 35.11010985147385\n",
      "train loss 33.82436424035293\n",
      "train loss 33.2272458384114\n",
      "Epoch 36 avg Valid loss: 31.409\n",
      "Epoch 36 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 22.526243209838867\n",
      "train loss 28.399590810139976\n",
      "train loss 34.04828955910423\n",
      "train loss 32.81476318836212\n",
      "train loss 31.66446822030203\n",
      "train loss 32.73475474577683\n",
      "train loss 32.84609963816981\n",
      "Epoch 37 avg Valid loss: 31.654\n",
      "Epoch 37 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 13.218456268310547\n",
      "train loss 29.466960350672405\n",
      "train loss 35.06970670006492\n",
      "train loss 36.662657886743546\n",
      "train loss 34.81607707341512\n",
      "train loss 31.00691146116991\n",
      "train loss 32.281464207556944\n",
      "Epoch 38 avg Valid loss: 32.944\n",
      "Epoch 38 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 14.659740447998047\n",
      "train loss 41.70463943481445\n",
      "train loss 34.94363182241266\n",
      "train loss 36.78244760632515\n",
      "train loss 35.34304425829933\n",
      "train loss 35.69445732923654\n",
      "train loss 32.757856230581964\n",
      "Epoch 39 avg Valid loss: 31.401\n",
      "Epoch 39 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 12.244267463684082\n",
      "train loss 22.798788905143738\n",
      "train loss 25.23610247265209\n",
      "train loss 28.040876582264904\n",
      "train loss 30.650163343974523\n",
      "train loss 33.98001888165107\n",
      "train loss 32.65315085841763\n",
      "Epoch 40 avg Valid loss: 31.410\n",
      "Epoch 40 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 34.85634231567383\n",
      "train loss 23.10142429669698\n",
      "train loss 28.529066649350252\n",
      "train loss 31.44749322533607\n",
      "train loss 31.644722461700436\n",
      "train loss 31.364022163244393\n",
      "train loss 31.87326202084941\n",
      "Epoch 41 avg Valid loss: 31.625\n",
      "Epoch 41 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 78.50015258789062\n",
      "train loss 35.57917642593384\n",
      "train loss 34.40815700184215\n",
      "train loss 32.728921473026276\n",
      "train loss 32.67094130743117\n",
      "train loss 32.79263192873735\n",
      "train loss 32.65840860336058\n",
      "Epoch 42 avg Valid loss: 31.405\n",
      "Epoch 42 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 28.95844268798828\n",
      "train loss 26.35266923904419\n",
      "train loss 24.70024316961115\n",
      "train loss 29.323232293128967\n",
      "train loss 30.109038307553245\n",
      "train loss 29.750143271226147\n",
      "train loss 33.209107583568944\n",
      "Epoch 43 avg Valid loss: 32.942\n",
      "Epoch 43 Valid accuracy: 68.0% (17 of 25 right)\n",
      "\n",
      "train loss 36.39912414550781\n",
      "train loss 23.758826732635498\n",
      "train loss 28.509421608664773\n",
      "train loss 29.654760479927063\n",
      "train loss 28.349561776433674\n",
      "train loss 28.892395748541905\n",
      "train loss 29.598523259162903\n",
      "Epoch 44 avg Valid loss: 32.979\n",
      "Epoch 44 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 45.01849365234375\n",
      "train loss 53.05464680989583\n",
      "train loss 43.13918157057328\n",
      "train loss 39.14885723590851\n",
      "train loss 35.389341252190725\n",
      "train loss 34.42088804795192\n",
      "train loss 32.06424607769136\n",
      "Epoch 45 avg Valid loss: 31.407\n",
      "Epoch 45 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 42.255821228027344\n",
      "train loss 31.75071907043457\n",
      "train loss 29.852095972407948\n",
      "train loss 32.2849595695734\n",
      "train loss 32.23055810020083\n",
      "train loss 32.91918004476107\n",
      "train loss 31.7330705273536\n",
      "Epoch 46 avg Valid loss: 31.511\n",
      "Epoch 46 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 24.34720802307129\n",
      "train loss 24.125057816505432\n",
      "train loss 30.48477240042253\n",
      "train loss 34.52254556119442\n",
      "train loss 29.82857589494614\n",
      "train loss 30.299754610428437\n",
      "train loss 31.850470781326283\n",
      "Epoch 47 avg Valid loss: 31.346\n",
      "Epoch 47 Valid accuracy: 76.0% (19 of 25 right)\n",
      "\n",
      "train loss 29.657161712646484\n",
      "train loss 32.494854847590126\n",
      "train loss 30.749558752233334\n",
      "train loss 30.005961984395984\n",
      "train loss 30.761261054447722\n",
      "train loss 31.130988102692825\n",
      "train loss 30.644173422167377\n",
      "Epoch 48 avg Valid loss: 31.419\n",
      "Epoch 48 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 29.43727684020996\n",
      "train loss 35.37077522277832\n",
      "train loss 33.797783244739875\n",
      "train loss 35.41321474313735\n",
      "train loss 35.21722975231352\n",
      "train loss 33.55772040440486\n",
      "train loss 32.62899454178349\n",
      "Epoch 49 avg Valid loss: 31.841\n",
      "Epoch 49 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n",
      "train loss 44.86838912963867\n",
      "train loss 26.15802105267843\n",
      "train loss 30.184021559628572\n",
      "train loss 32.78100934624672\n",
      "train loss 33.074332577841616\n",
      "train loss 31.95103830557603\n",
      "train loss 31.14984753824049\n",
      "Epoch 50 avg Valid loss: 31.508\n",
      "Epoch 50 Valid accuracy: 28.0% (7 of 25 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(params['n_epochs']):\n",
    "    train_loss = train_one_epoch(epoch, model, loss_fn, optimizer, train_loader)\n",
    "    train_losses+= [train_loss]\n",
    "    valid_loss, accuracy, correct, total = test_one_epoch(epoch, model, loss_fn, valid_loader, len_val)\n",
    "    valid_losses+=[valid_loss]\n",
    "    print('Epoch {} avg Valid loss: {:.3f}'.format(epoch+1, valid_loss))\n",
    "    print('Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n'.format(epoch+1, accuracy, correct, total))\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_fn,\n",
    "            }, 'checkpoint.tar')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e920b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 31.517\n",
      "Test accuracy: 76.0% (19 of 25 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "checkpoint = torch.load('checkpoint.tar')\n",
    "loaded_model = Net(params['num_classes'])\n",
    "loaded_model.to(params[\"device\"])\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "loaded_criterion = checkpoint['loss']\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "last_epoch = checkpoint['epoch']+1\n",
    "\n",
    "test_loss, accuracy, correct, total = test_one_epoch(None, loaded_model, loaded_criterion, valid_loader, len_val)\n",
    "\n",
    "print('Test loss: {:.3f}'.format(test_loss))\n",
    "print('Test accuracy: {:.1%} ({} of {} right)\\n'.format(accuracy, correct, total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d2f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66cfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
