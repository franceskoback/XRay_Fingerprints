{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6dbd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import timm \n",
    "import torch\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "import albumentations as A\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "METADATA_SUBSET_PATH = \"/Users/franceskoback/Documents/research/pytorch_1/metadata_100subset_df.csv\"\n",
    "\n",
    "def get_manufacturer_labels(encoder, target_variable = \"(0008, 0070) Manufacturer\"):\n",
    "    df = pd.read_csv(METADATA_SUBSET_PATH)\n",
    "    df[\"id\"] = df[\"id\"].astype(\"str\").str.zfill(8)\n",
    "    df[\"code\"] = encoder.fit_transform(df[target_variable])\n",
    "    dictionary= {row[\"id\"]: row[\"code\"] for i, row in df.iterrows()}\n",
    "    keys = dictionary.keys()\n",
    "    values = dictionary.values()\n",
    "    return dictionary\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.img_dir = \"/Users/franceskoback/Documents/research/pytorch_1/xray_subsets\"\n",
    "        self.images = glob.glob(os.path.join(self.img_dir, \"*.npy\")) \n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.label_map = get_manufacturer_labels(self.le)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.fromarray(np.load(img_path)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "        image=normalize(image)\n",
    "        xray_id = os.path.basename(img_path).replace(\".npy\", \"\")\n",
    "        label= self.label_map[xray_id]\n",
    "        label= torch.as_tensor(label)\n",
    "        label= F.one_hot(label,num_classes=10)\n",
    "        print(label)\n",
    "        #print(\"image is\")\n",
    "       # print(image)\n",
    "        #print(\"label is\")\n",
    "        #print(label)\n",
    "        return (image, label)\n",
    "        #return {\"image\": image, \"label\": self.label_map[xray_id]}\n",
    "\n",
    "def train_val_test_dataset(dataset, val_split=0.20):\n",
    "    train_idx, rem_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "\n",
    "    Test_size=0.5 # split equally between validataion and test sets \n",
    "\n",
    "    val_idx, test_idx  = train_test_split(list(rem_idx), test_size=Test_size)\n",
    "\n",
    "\n",
    "\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    datasets['test'] = Subset(dataset, test_idx)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261d85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79162b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.98403772  2.02336931  1.98232765 ...  1.99771827  1.97805248\n",
      "   2.23712797]\n",
      " [ 1.97292227  1.93273564  1.8797235  ...  1.99942834  1.86946308\n",
      "   2.16017485]\n",
      " [ 1.88399867  1.85407246  1.75574348 ...  1.89169398  1.80362542\n",
      "   2.15846478]\n",
      " ...\n",
      " [ 0.88360817 -0.78456437 -0.68709042 ... -0.63749842 -0.63236821\n",
      "  -0.63151317]\n",
      " [ 0.89985383 -0.78456437 -0.67854008 ... -0.63578835 -0.62894807\n",
      "  -0.62894807]\n",
      " [ 0.89301355 -0.76575361 -0.67854008 ... -0.62894807 -0.6246729\n",
      "  -0.62381786]]\n",
      "tensor([[[0.0039, 0.0078, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0039, 0.0078, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0039, 0.0078, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_array = np.load('/Users/franceskoback/Documents/research/pytorch_1/xray_subsets/00098404.npy')\n",
    "from matplotlib import pyplot as plt\n",
    "print(img_array)\n",
    "image_ = Image.fromarray(img_array).convert(\"RGB\")\n",
    "#print(image_)\n",
    "image_ = transforms.ToTensor()(image_)\n",
    "print(image_)\n",
    "print(image_.shape)\n",
    "#np.savetxt('mytorch.txt', image_.numpy())\n",
    "\n",
    "#plt.imshow(img_array, cmap='gray')\n",
    "#plt.show()\n",
    "#print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e15a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset()\n",
    "for i, data in enumerate(dataset,0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        #print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7225df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "80\n",
      "Training length 80\n",
      "Validation length 10\n",
      "Testing length 10\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset()\n",
    "datasets = train_val_test_dataset(dataset)\n",
    "print(len(datasets['train'].dataset)) #6\n",
    "train_dataset= datasets['train']\n",
    "val_dataset= datasets['val']\n",
    "test_dataset= datasets['test']\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    val_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(len(train_loader.dataset)) #6 \n",
    "len_train=len(datasets['train'])\n",
    "len_val= len(datasets['val'])\n",
    "len_test= len(datasets['test'])\n",
    "\n",
    "#print(test_dataset.targets)\n",
    "print(\"Training length\", len(train_loader))\n",
    "print(\"Validation length\", len(valid_loader))\n",
    "print(\"Testing length\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becbf6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "         #get the inputs\n",
    "       inputs, labels = data\n",
    "       #print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80723e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def Net(num_classes):\n",
    "    model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "    \n",
    "    # Freeze parameters so we don't backprop through them\n",
    "    #for param in model.parameters():\n",
    "    #    param.requires_grad = False\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                             ('fc1', nn.Linear(2048, 1024)), # used to be 2048 x 1024\n",
    "                             ('relu', nn.ReLU()),\n",
    "                             ('fc2', nn.Linear(1024, 256)), # can experiment with these #s \n",
    "                             ('relu', nn.ReLU()),\n",
    "                             ('fc3', nn.Linear(256, num_classes))#, # used to be num_classes\n",
    "                             #('output', nn.LogSoftmax(dim=1))\n",
    "                             ]))\n",
    "\n",
    "    model.fc = classifier\n",
    "    return model\n",
    "\n",
    "params = {\n",
    "    \"model\": \"resnet50\",\n",
    "    #\"device\": \"cuda\",\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 10, #64\n",
    "    \"num_workers\": 1, #20\n",
    "    \"n_epochs\": 50, #100\n",
    "    \"image_size\": 224, \n",
    "    \"in_channels\": 2, #3\n",
    "    \"num_classes\": 10, #12\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "model = Net(params['num_classes'])\n",
    "model.eval().to(params[\"device\"])\n",
    "#loss_fn = nn.NLLLoss() \n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = params['lr'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e598f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(valid_loader))\n",
    "print(len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dee2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, loader, device = \"cpu\"):\n",
    "    #put model in training state\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    print(\"length of loader\")\n",
    "    print(len(loader))\n",
    "\n",
    "    for batch_idx, (img,label) in enumerate(loader,0):  \n",
    "        inputs =img\n",
    "        labels = label\n",
    "        #print(\"label\")\n",
    "        #print(label)\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad() # sets all grads to None \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        outputs = torch.zeros_like(labels).scatter_(1, pred.unsqueeze(1), 1.)\n",
    "        #print(\"outputs are\",outputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "         #   print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            #running_loss=0\n",
    "          #  i=i+1\n",
    "        \n",
    "        train_loss+= ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "        # if batch_idx%5==0:\n",
    "        #     print('train loss', train_loss)\n",
    "        if batch_idx % 5 == 0:\n",
    "            loss, current = loss.item(), batch_idx * len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{len(loader):>5d}]\")\n",
    "    \n",
    "    \n",
    "    print('Epoch {} avg Training loss: {:.3f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "    return model, train_loss\n",
    "\n",
    "def test_one_epoch(epoch, model, loss_fn, loader, len_val, device = \"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"length of loader\")\n",
    "    print(len(loader))\n",
    "    #pbar = tqdm(enumerate(test_loader), total = len(test_loader))\n",
    "    running_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    #for step, (imgs, labels) in pbar:\n",
    "    for batch_idx, (img,label) in enumerate(loader,0):    \n",
    "        inputs =img\n",
    "        #print('img')\n",
    "        #print(img)\n",
    "        labels = label\n",
    "        #print(\"label\")\n",
    "        #print(label)\n",
    "        \n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        \n",
    "        log_preds = model(inputs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "\n",
    "\n",
    "        preds = torch.exp(log_preds)\n",
    "        running_loss+=((1 / (batch_idx + 1)) * (loss.data.item() - running_loss))\n",
    "        \n",
    "        #calculate accuracy\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "        actual_labels+= list(labels.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    \n",
    "    accuracy = ((np.array(pred_labels)==np.array(actual_labels)).sum())/np.array(actual_labels).size #size of test set\n",
    "    correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "    total = np.array(actual_labels).size\n",
    "    \n",
    "    \n",
    "    return running_loss, accuracy, correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f203fbb",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d563e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of loader\n",
      "80\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m valid_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(params[\u001b[39m'\u001b[39m\u001b[39mn_epochs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m----> 5\u001b[0m     train_loss \u001b[39m=\u001b[39m train_one_epoch(epoch, model, loss_fn, optimizer, train_loader)\n\u001b[1;32m      6\u001b[0m     train_losses\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [train_loss]\n\u001b[1;32m      7\u001b[0m     valid_loss, accuracy, correct, total \u001b[39m=\u001b[39m test_one_epoch(epoch, model, loss_fn, valid_loader, len_val)\n",
      "Cell \u001b[0;32mIn [12], line 26\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loss_fn, optimizer, loader, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m#print(\"outputs are\",outputs)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#running_loss += loss.item()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m#if i % 2000 == 1999:    # print every 2000 mini-batches\u001b[39;00m\n\u001b[1;32m     33\u001b[0m  \u001b[39m#   print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39m#running_loss=0\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   \u001b[39m#  i=i+1\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(params['n_epochs']):\n",
    "    train_loss = train_one_epoch(epoch, model, loss_fn, optimizer, train_loader)\n",
    "    train_losses+= [train_loss]\n",
    "    valid_loss, accuracy, correct, total = test_one_epoch(epoch, model, loss_fn, valid_loader, len_val)\n",
    "    valid_losses+=[valid_loss]\n",
    "    print('Epoch {} avg Valid loss: {:.3f}'.format(epoch+1, valid_loss))\n",
    "    print('Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n'.format(epoch+1, accuracy, correct, total))\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_fn,\n",
    "            }, 'checkpoint.tar')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004682ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e920b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of loader\n",
      "10\n",
      "Test loss: 71.610\n",
      "Test accuracy: 0.0% (0 of 10 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "checkpoint = torch.load('checkpoint.tar')\n",
    "loaded_model = Net(params['num_classes'])\n",
    "loaded_model.to(params[\"device\"])\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "loaded_criterion = checkpoint['loss']\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "last_epoch = checkpoint['epoch']+1\n",
    "\n",
    "test_loss, accuracy, correct, total = test_one_epoch(None, loaded_model, loaded_criterion, test_loader, len_val)\n",
    "\n",
    "print('Test loss: {:.3f}'.format(test_loss))\n",
    "print('Test accuracy: {:.1%} ({} of {} right)\\n'.format(accuracy, correct, total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d2f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66cfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
