{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6dbd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import timm \n",
    "import torch\n",
    "\n",
    "# I'm adding this in\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "METADATA_SUBSET_PATH = \"/Users/franceskoback/Documents/research/pytorch_1/metadata_100subset_df.csv\"\n",
    "\n",
    "def get_manufacturer_labels(encoder, target_variable = \"(0008, 0070) Manufacturer\"):\n",
    "    df = pd.read_csv(METADATA_SUBSET_PATH)\n",
    "    df[\"id\"] = df[\"id\"].astype(\"str\").str.zfill(8)\n",
    "    df[\"code\"] = encoder.fit_transform(df[target_variable])\n",
    "    \n",
    "    return {row[\"id\"]: row[\"code\"] for i, row in df.iterrows()}\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #self.img_dir = \"/Users/franceskoback/Documents/research/pytorch_1/imagezz\"\n",
    "        self.img_dir = \"/Users/franceskoback/Documents/research/pytorch_1/xray_subsets\"\n",
    "\n",
    "        self.images = glob.glob(os.path.join(self.img_dir, \"*.npy\")) \n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.label_map = get_manufacturer_labels(self.le)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.fromarray(np.load(img_path)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "        xray_id = os.path.basename(img_path).replace(\".npy\", \"\")\n",
    "        \n",
    "        return {\"image\": image, \"label\": self.label_map[xray_id]}\n",
    "\n",
    "def train_val_dataset(dataset, val_split=0.25):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7225df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "Training length 4\n",
      "Validation length 2\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset()\n",
    "datasets = train_val_dataset(dataset)\n",
    "print(len(datasets['train'].dataset)) #6\n",
    "#datasets['train'].dataset, batch_size=params[\"batch_size\"], shuffle=True\n",
    "train_loader = DataLoader(\n",
    "    datasets['train'].dataset, batch_size=3, shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    datasets['val'].dataset, batch_size=3, shuffle=True\n",
    ")\n",
    "print(len(train_loader.dataset)) #6 \n",
    "len_train=len(datasets['train'])\n",
    "len_val= len(datasets['val'])\n",
    "print(\"Training length\", len(datasets['train']))\n",
    "print(\"Validation length\", len(datasets['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80723e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Net(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    #model=timm.create_model(model,pretrained= True)\n",
    "    #model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    #model= efn.EfficientNetB0(weights='imagenet')\n",
    "    # Freeze parameters so we don't backprop through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                              ('fc1', nn.Linear(2048, 1024)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('fc2', nn.Linear(1024, 256)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('fc3', nn.Linear(256, num_classes)),\n",
    "                              ('output', nn.LogSoftmax(dim=1))\n",
    "                              ]))\n",
    "\n",
    "    model.fc = classifier\n",
    "    return model\n",
    "\n",
    "params = {\n",
    "    \"model\": \"resnet50\",\n",
    "    #\"device\": \"cuda\",\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 3, #64\n",
    "    \"num_workers\": 1, #20\n",
    "    \"n_epochs\": 50, #100\n",
    "    \"image_size\": 224, \n",
    "    \"in_channels\": 3, #3\n",
    "    \"num_classes\": 3, #12\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "model = Net(params['num_classes'])\n",
    "model.to(params[\"device\"])\n",
    "#loss_fn = nn.NLLLoss() # we want MSE loss i think \n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dee2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device = \"cpu\"):\n",
    "    #put model in training state\n",
    "    model.train()\n",
    "    #i=0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "\n",
    "    for batch_idx, img_dicts in enumerate(train_loader,0):  #used to be enumerate(train_loader)\n",
    "        inputs = img_dicts[\"image\"] #ORIGINAL ONE\n",
    "        labels = img_dicts[\"label\"]  # ORIGINAL ONE\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        #print(inputs.shape, labels.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() # do we need this or not? sets all grads to None \n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "         #   print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            #running_loss=0\n",
    "          #  i=i+1\n",
    "\n",
    "        \n",
    "        \n",
    "        #\n",
    "    \n",
    "        train_loss+= ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "        if batch_idx%5==0:\n",
    "            print('train loss', train_loss)\n",
    "    \n",
    "    #print('Epoch {} avg Training loss: {:.3f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "    return model, train_loss\n",
    "\n",
    "def test_one_epoch(epoch, model, loss_fn, loader, len_val, device = \"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    #pbar = tqdm(enumerate(test_loader), total = len(test_loader))\n",
    "    running_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    #for step, (imgs, labels) in pbar:\n",
    "    for batch_idx, img_dicts in enumerate(loader,0):    \n",
    "        inputs = img_dicts[\"image\"] #ORIGINAL ONE\n",
    "        labels = img_dicts[\"label\"]  # ORIGINAL ONE\n",
    "        \n",
    "        inputs = Variable(inputs.to(device).float())\n",
    "        labels = Variable(labels.to(device).float())\n",
    "        \n",
    "        log_preds = model(inputs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "        \n",
    "        preds = torch.exp(log_preds)\n",
    "        running_loss+=((1 / (batch_idx + 1)) * (loss.data.item() - running_loss))\n",
    "        \n",
    "        #calculate accuracy\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "        actual_labels+= list(labels.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    \n",
    "    accuracy = ((np.array(pred_labels)==np.array(actual_labels)).sum())/len_val #size of test set\n",
    "    correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "    total = len_val\n",
    "    \n",
    "    \n",
    "    return running_loss, accuracy, correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f203fbb",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d563e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 10.457435607910156\n",
      "Epoch 1 avg Valid loss: 10.429\n",
      "Epoch 1 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 6.120249271392822\n",
      "Epoch 2 avg Valid loss: 10.388\n",
      "Epoch 2 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 13.340846061706543\n",
      "Epoch 3 avg Valid loss: 10.411\n",
      "Epoch 3 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 10.504226684570312\n",
      "Epoch 4 avg Valid loss: 10.351\n",
      "Epoch 4 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.633596420288086\n",
      "Epoch 5 avg Valid loss: 10.448\n",
      "Epoch 5 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 12.187188148498535\n",
      "Epoch 6 avg Valid loss: 10.362\n",
      "Epoch 6 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 3.3581321239471436\n",
      "Epoch 7 avg Valid loss: 10.369\n",
      "Epoch 7 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 5.065195560455322\n",
      "Epoch 8 avg Valid loss: 10.473\n",
      "Epoch 8 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 13.272343635559082\n",
      "Epoch 9 avg Valid loss: 10.420\n",
      "Epoch 9 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 13.418072700500488\n",
      "Epoch 10 avg Valid loss: 10.347\n",
      "Epoch 10 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.290302276611328\n",
      "Epoch 11 avg Valid loss: 10.345\n",
      "Epoch 11 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 6.135753154754639\n",
      "Epoch 12 avg Valid loss: 10.384\n",
      "Epoch 12 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 9.249540328979492\n",
      "Epoch 13 avg Valid loss: 10.442\n",
      "Epoch 13 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 7.50078821182251\n",
      "Epoch 14 avg Valid loss: 10.506\n",
      "Epoch 14 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 3.345822334289551\n",
      "Epoch 15 avg Valid loss: 10.377\n",
      "Epoch 15 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.210310935974121\n",
      "Epoch 16 avg Valid loss: 10.505\n",
      "Epoch 16 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 7.572425842285156\n",
      "Epoch 17 avg Valid loss: 10.402\n",
      "Epoch 17 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 3.3092854022979736\n",
      "Epoch 18 avg Valid loss: 10.420\n",
      "Epoch 18 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 15.727164268493652\n",
      "Epoch 19 avg Valid loss: 10.466\n",
      "Epoch 19 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 14.553196907043457\n",
      "Epoch 20 avg Valid loss: 10.394\n",
      "Epoch 20 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.310590744018555\n",
      "Epoch 21 avg Valid loss: 10.410\n",
      "Epoch 21 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 13.429117202758789\n",
      "Epoch 22 avg Valid loss: 10.427\n",
      "Epoch 22 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.63749885559082\n",
      "Epoch 23 avg Valid loss: 10.400\n",
      "Epoch 23 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 13.298048973083496\n",
      "Epoch 24 avg Valid loss: 10.415\n",
      "Epoch 24 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 15.776097297668457\n",
      "Epoch 25 avg Valid loss: 10.363\n",
      "Epoch 25 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 6.1340765953063965\n",
      "Epoch 26 avg Valid loss: 10.360\n",
      "Epoch 26 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 13.388019561767578\n",
      "Epoch 27 avg Valid loss: 10.374\n",
      "Epoch 27 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 12.22005844116211\n",
      "Epoch 28 avg Valid loss: 10.398\n",
      "Epoch 28 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 11.589519500732422\n",
      "Epoch 29 avg Valid loss: 10.411\n",
      "Epoch 29 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.503143310546875\n",
      "Epoch 30 avg Valid loss: 10.383\n",
      "Epoch 30 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 13.389513969421387\n",
      "Epoch 31 avg Valid loss: 10.387\n",
      "Epoch 31 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 14.724153518676758\n",
      "Epoch 32 avg Valid loss: 10.368\n",
      "Epoch 32 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 9.159708976745605\n",
      "Epoch 33 avg Valid loss: 10.379\n",
      "Epoch 33 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 10.266185760498047\n",
      "Epoch 34 avg Valid loss: 10.378\n",
      "Epoch 34 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 13.339778900146484\n",
      "Epoch 35 avg Valid loss: 10.430\n",
      "Epoch 35 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 3.3526504039764404\n",
      "Epoch 36 avg Valid loss: 10.360\n",
      "Epoch 36 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 8.565052032470703\n",
      "Epoch 37 avg Valid loss: 10.383\n",
      "Epoch 37 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 10.59011459350586\n",
      "Epoch 38 avg Valid loss: 10.421\n",
      "Epoch 38 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 8.537315368652344\n",
      "Epoch 39 avg Valid loss: 10.433\n",
      "Epoch 39 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 10.511043548583984\n",
      "Epoch 40 avg Valid loss: 10.424\n",
      "Epoch 40 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 8.52090835571289\n",
      "Epoch 41 avg Valid loss: 10.411\n",
      "Epoch 41 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 17.45264434814453\n",
      "Epoch 42 avg Valid loss: 10.413\n",
      "Epoch 42 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 15.74620246887207\n",
      "Epoch 43 avg Valid loss: 10.397\n",
      "Epoch 43 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 7.445948123931885\n",
      "Epoch 44 avg Valid loss: 10.378\n",
      "Epoch 44 Valid accuracy: 50.0% (1 of 2 right)\n",
      "\n",
      "train loss 12.305614471435547\n",
      "Epoch 45 avg Valid loss: 10.430\n",
      "Epoch 45 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.576095581054688\n",
      "Epoch 46 avg Valid loss: 10.383\n",
      "Epoch 46 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.5120267868042\n",
      "Epoch 47 avg Valid loss: 10.420\n",
      "Epoch 47 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 12.232275009155273\n",
      "Epoch 48 avg Valid loss: 10.383\n",
      "Epoch 48 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 10.252313613891602\n",
      "Epoch 49 avg Valid loss: 10.404\n",
      "Epoch 49 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n",
      "train loss 9.173325538635254\n",
      "Epoch 50 avg Valid loss: 10.392\n",
      "Epoch 50 Valid accuracy: 100.0% (2 of 2 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(params['n_epochs']):\n",
    "    train_loss = train_one_epoch(epoch, model, loss_fn, optimizer, train_loader)\n",
    "    train_losses+= [train_loss]\n",
    "    valid_loss, accuracy, correct, total = test_one_epoch(epoch, model, loss_fn, valid_loader, len_val)\n",
    "    valid_losses+=[valid_loss]\n",
    "    print('Epoch {} avg Valid loss: {:.3f}'.format(epoch+1, valid_loss))\n",
    "    print('Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n'.format(epoch+1, accuracy, correct, total))\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_fn,\n",
    "            }, 'checkpoint.tar')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e920b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 10.360\n",
      "Test accuracy: 100.0% (2 of 2 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "checkpoint = torch.load('checkpoint.tar')\n",
    "loaded_model = Net(params['num_classes'])\n",
    "loaded_model.to(params[\"device\"])\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "loaded_criterion = checkpoint['loss']\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "last_epoch = checkpoint['epoch']+1\n",
    "\n",
    "test_loss, accuracy, correct, total = test_one_epoch(None, loaded_model, loaded_criterion, valid_loader, len_val)\n",
    "\n",
    "print('Test loss: {:.3f}'.format(test_loss))\n",
    "print('Test accuracy: {:.1%} ({} of {} right)\\n'.format(accuracy, correct, total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d2f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66cfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
